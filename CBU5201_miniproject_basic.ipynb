{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e483a6c7-08b5-4c81-8cdd-a6f0ab2e81ed",
   "metadata": {},
   "source": [
    "#### 1 Author ####\n",
    "Student Name:Rui Chen\n",
    "Student ID:210978863"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7504c8a-e5b1-4916-915e-e48ce17a4d85",
   "metadata": {},
   "source": [
    "#### 2 Problem formulation ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b716662-9958-4b95-a009-4d8ea2d85bc8",
   "metadata": {},
   "source": [
    "Based on Genki4k dataset which is a dataset from \"http://mplab.ucsd.edu\" and the title as \"the MPLab GENKI Database, GENKI-4K Subset\", we need to finish two tasks, smile detection and 3D head pose estimation.Our goal is trainning a model to correctly predict if the person is smilling and his head pose after we input a image.\n",
    "Every image was labeled as \"1\" or \"0\" which means \"smile\" or \"unsmile\", there are also three other labels for head pose prediction.Because we already have the labels for all items in the datasets,so we choose classification which is supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131827d-7491-4018-9ce0-4232aaff5616",
   "metadata": {},
   "source": [
    "#### 3 Machine Learning pipeline ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00817bd5-9db3-4b3f-9b39-a841bd170289",
   "metadata": {},
   "source": [
    "There are four main step to do the task:data preprocess,split data,train the model,test(evaluate) the model\n",
    "\n",
    "In this task,we use two models to do smile-detection and head pose estimation.\n",
    "The first one is classification for smile-detection, after input, the output is the state and probability.\n",
    "The second one is regression, using a regression model to predict the yaw,pitch and roll of a image, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a3cfd-ebc1-4974-8f2c-ff2f61e00695",
   "metadata": {},
   "source": [
    "#### 4 Transformation Stage ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de239a2f-9b83-46d6-ad77-7dca412c6f03",
   "metadata": {},
   "source": [
    "In the transfomation stage, we need to transform the data so that it can be used to fit a model. For example, we do some preproces, data augmentation etc.I use 68_face_landmarks to extract useful face information. During the process of extracting faces, simple geometric transformations are applied by cropping the facial region and resizing it and this process can be seen as a mild data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2fc9e10-de9a-48df-acff-159bda3bdc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# File paths for images\n",
    "image_path1 = 'genki4k/files/file0001.jpg'\n",
    "image_path2 = 'genki4k/files(preprocess)/file1.jpg'\n",
    "\n",
    "# Display the two images\n",
    "display(Image(filename=image_path1))\n",
    "display(Image(filename=image_path2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a7a29-caf2-43ec-b87a-fff36b570cb3",
   "metadata": {},
   "source": [
    "#### 5 Modelling ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef5158-d14d-4d4b-b1d2-263cdbb0b7f4",
   "metadata": {},
   "source": [
    "This code defines a PyTorch module for constructing ResNet models and this provides flexible tools for constructing ResNet models so that different ResNet variants like `resnet34`, `resnet50`, `resnet101`, `resnext50_32x4d`, `resnext101_32x8d` can be easily chosen. \n",
    "\r",
    "1.BasicBlock class:\r\n",
    "This class defines the basic residual block of ResNet, consisting of two convolutional layers and an identity mappinc2.k.\r\n",
    "Bottleneck cls:\r\n",
    "\r\n",
    "This class defines the bottleneck residual block of ResNet, consisting of three convolutional layers and an identity ma 3.block.\r\n",
    "ResNelass:\r\n",
    "\r\n",
    "This class is the main definition for the entire Reset model.\r\n",
    "The __init__ method initializes various layers of the ResNet model, including convolutional layers, batch normalization lyers, etc.\r\n",
    "The _make_layer method constructs the layers of ResNet, including multiple resiual blocks.\r\n",
    "The forward method implements the entire forward pass of the i4.er is optional.\r\n",
    "WeighInitialization:\r\n",
    "\r\n",
    "At the end of the __init__ method, the nn.init.kaiming_normal_ method is used to initialize the weights of all convolutional layers using th Kaiming ini\n",
    "tializ mHere are some reason that I chose resnet:chFirstly, addressing the vanishing gradient problem. ient proble** In deep neural networks, the vanishing gradient problem makes training deep networks challenging. ResNet mitigates this issue by allowing information to be directly passed between layers through residual making it easier to train deep networks.  making it easSecondly,it can also support for deeper tworks and i\n",
    "Improved generalizacetion performan.\n",
    "\n",
    "As for resnet34,it has lower model complexity, resulting in fewer model parameters and lower computational costs. This makes it easier to train and deploy, especially in resource-constrained scenarios.Secondly it is s\n",
    "Suitable for medium-sized datase like our datasets and get excellent performance.sks.e.aints.ng in practical tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccaba34-e581-442a-8028-94ae50ff973b",
   "metadata": {},
   "source": [
    "It is loading weight. This process is called after creating the model, and its purpose is to initialize the model's parameters with the weights learned from a pre-trained model. This way, the model inherits the feature representations learned by the pre-trained model and can be fine-tuned or further trained for specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344fb29-d5c9-4c5c-bc9f-6788252e04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from resnet import resnet34\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # load pretrain weights\n",
    "    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "    model_weight_path = \"./resnet34-pre.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "\n",
    "    net = resnet34()\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    # change fc layer structure\n",
    "    in_channel = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_channel, 5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b67070-578e-46f7-8699-787a6badadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Note: In the original paper, on the main branch of the dashed residual structure, the first 1x1 convolutional layer has a step of 2 and the second 3x3 convolutional layer has a step of 1.\n",
    "    However, in the official pytorch implementation, the first 1x1 convolutional layer has a step of 1, and the second 3x3 convolutional layer has a step of 2.\n",
    "    The advantage of doing this is that it can improve the accuracy of top1 by about 0.5%.\n",
    "    See also Resnet v1.5 https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1, downsample=None,\n",
    "                 groups=1, width_per_group=64):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        width = int(out_channel * (width_per_group / 64.)) * groups\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=width,\n",
    "                               kernel_size=1, stride=1, bias=False)  # squeeze channels\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv2 = nn.Conv2d(in_channels=width, out_channels=width, groups=groups,\n",
    "                               kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        # -----------------------------------------\n",
    "        self.conv3 = nn.Conv2d(in_channels=width, out_channels=out_channel*self.expansion,\n",
    "                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels\n",
    "        self.bn3 = nn.BatchNorm2d(out_channel*self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 blocks_num,\n",
    "                 num_classes=1000,\n",
    "                 include_top=True,\n",
    "                 groups=1,\n",
    "                 width_per_group=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.include_top = include_top\n",
    "        self.in_channel = 64\n",
    "\n",
    "        self.groups = groups\n",
    "        self.width_per_group = width_per_group\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
    "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
    "        if self.include_top:\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, channel, block_num, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channel * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channel,\n",
    "                            channel,\n",
    "                            downsample=downsample,\n",
    "                            stride=stride,\n",
    "                            groups=self.groups,\n",
    "                            width_per_group=self.width_per_group))\n",
    "        self.in_channel = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            layers.append(block(self.in_channel,\n",
    "                                channel,\n",
    "                                groups=self.groups,\n",
    "                                width_per_group=self.width_per_group))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.avgpool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet34(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnet50(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnet101(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)\n",
    "\n",
    "\n",
    "def resnext50_32x4d(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\n",
    "    groups = 32\n",
    "    width_per_group = 4\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3],\n",
    "                  num_classes=num_classes,\n",
    "                  include_top=include_top,\n",
    "                  groups=groups,\n",
    "                  width_per_group=width_per_group)\n",
    "\n",
    "\n",
    "def resnext101_32x8d(num_classes=1000, include_top=True):\n",
    "    # https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\n",
    "    groups = 32\n",
    "    width_per_group = 8\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3],\n",
    "                  num_classes=num_classes,\n",
    "                  include_top=include_top,\n",
    "                  groups=groups,\n",
    "                  width_per_group=width_per_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fcc82-d3c8-4888-8ad9-1020ccc351d1",
   "metadata": {},
   "source": [
    "#### 6 Methodology ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6a63b-2ffd-4e4b-90ea-054ff7c45514",
   "metadata": {},
   "source": [
    "Step 1 preprocess (The process is detailed in Part 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c127047-a744-45d6-b8c8-14d64f7c1930",
   "metadata": {},
   "source": [
    "The first step of this task is data preprocessing.In this task, no matter smile detection or head pose estimation we just need pixels that contain information of face.Here we import some useful packages to help us extract face and data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ebd7d-62e6-4d0c-b7d3-7395e6ce561b",
   "metadata": {},
   "source": [
    "Step 2 split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f795f3d0-a284-43fe-b367-d450fcfc820d",
   "metadata": {},
   "source": [
    "Before training, we should split the dataset.In this task,firstly we split the images into two folders,\"smile\" and \"unsmile\" through the given labels.Basic machine learning methodologies include two seperate tasks:training and testing, in the training stage,we fit a model to a dataset.We split the dataset for training and find the underlying pattern.\n",
    "In this project,we want to find a model to predict something,to get a better performance,after we get a model,we will use it and validate the accuracy of this model. So we need to split a dataset into three parts:train,test and validation,the ratio is (0.6,0.2,0.2).The code below shows how I split the dataset.\n",
    "Splitting data can also preventing overfitting, because it make sure that the model doesn't only fit one dataset but other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f661e2-484f-4192-8560-baf747ed8af7",
   "metadata": {},
   "source": [
    "We input the whole genki4k dataset and get 5 folders,\"smile\",\"unsmile\",\"train\",\"test\",\"val\".The \"smile\",\"unsmile\" folder is used to classify the items and the other three folders are used to store images for train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "380eae36-54b1-4db7-8cb5-ed30b8ed89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split into smile or unsmile done!\n",
      "split into train,test or val done!\n"
     ]
    }
   ],
   "source": [
    "def split_into_two(i=None):\n",
    "    # set the output path\n",
    "    data_folder = \"genki4k/files(preprocess)\"\n",
    "\n",
    "    # create two folders to split the data\n",
    "    os.makedirs(\"genki4k/files(splitdata)/smile\", exist_ok=True)\n",
    "    os.makedirs(\"genki4k/files(splitdata)/unsmile\", exist_ok=True)\n",
    "\n",
    "    #get all the files\n",
    "    files = os.listdir(data_folder)\n",
    "\n",
    "    # files.sort(key=lambda x: int(x.replace(\"file\", \"\").split('.')[0]))\n",
    "    fnames = ['file{}.jpg'.format(i) for i in range(1,2164)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(\"genki4k/files(preprocess)\", fname)\n",
    "        dst = os.path.join(\"genki4k/files(splitdata)/smile\", fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    fnames = ['file{}.jpg'.format(i) for i in range(2164,3879)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(\"genki4k/files(preprocess)\", fname)\n",
    "        dst = os.path.join(\"genki4k/files(splitdata)/unsmile\", fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    print(\"split into smile or unsmile done!\")\n",
    "\n",
    "def split_into_three():\n",
    "    # the ratio of [train,test,val] is [0.6,0.2,0.2]\n",
    "    split_ratio = [0.6, 0.2, 0.2]\n",
    "\n",
    "    # create output folders\n",
    "    output_folder = [\"genki4k/files(splitdata)/train\", \"genki4k/files(splitdata)/test\", \"genki4k/files(splitdata)/val\"]\n",
    "    for folder in output_folder:\n",
    "        os.makedirs(os.path.join(folder, \"smile\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(folder, \"unsmile\"), exist_ok=True)\n",
    "\n",
    "    # split smile folders into three folders, we use 'random' to assign images\n",
    "    smile_files = os.listdir(\"genki4k/files(splitdata)/smile\")\n",
    "    random.shuffle(smile_files)\n",
    "    total_smile_files = len(smile_files)\n",
    "    split_index_smile = [int(total_smile_files * split_ratio[0]), int(total_smile_files * (split_ratio[0] + split_ratio[1]))]\n",
    "\n",
    "    for i, file in enumerate(smile_files):\n",
    "        if i < split_index_smile[0]:\n",
    "            shutil.copy(os.path.join(\"genki4k/files(splitdata)/smile\", file), os.path.join(\"genki4k/files(splitdata)/train\", \"smile\", file))\n",
    "        elif i < split_index_smile[1]:\n",
    "            shutil.copy(os.path.join(\"genki4k/files(splitdata)/smile\", file), os.path.join(\"genki4k/files(splitdata)/test\", \"smile\", file))\n",
    "        else:\n",
    "            shutil.copy(os.path.join(\"genki4k/files(splitdata)/smile\", file), os.path.join(\"genki4k/files(splitdata)/val\", \"smile\", file))\n",
    "\n",
    "    # same as before\n",
    "    unsmile_files = os.listdir(\"genki4k/files(splitdata)/unsmile\")\n",
    "    random.shuffle(unsmile_files)\n",
    "    total_unsmile_files = len(unsmile_files)\n",
    "    split_index_unsmile = [int(total_unsmile_files * split_ratio[0]), int(total_unsmile_files * (split_ratio[0] + split_ratio[1]))]\n",
    "\n",
    "    for i, file in enumerate(unsmile_files):\n",
    "        if i < split_index_unsmile[0]:\n",
    "            shutil.copy(os.path.join(\"genki4k/files(splitdata)/unsmile\", file), os.path.join(\"genki4k/files(splitdata)/train\", \"unsmile\", file))\n",
    "        elif i < split_index_unsmile[1]:\n",
    "            shutil.copy(os.path.join(\"genki4k/files(splitdata)/unsmile\", file), os.path.join(\"genki4k/files(splitdata)/test\", \"unsmile\", file))\n",
    "        else:\n",
    "            shutil.copy(os.path.join(\"genki4k/files(splitdata)/unsmile\", file), os.path.join(\"genki4k/files(splitdata)/val\", \"unsmile\", file))\n",
    "\n",
    "    print(\"split into train,test or val done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_into_two()\n",
    "    split_into_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495395c-ebb5-49b2-95a2-61d5716640a7",
   "metadata": {},
   "source": [
    "Step 3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fdb0bc0-20eb-4e3b-b105-d7dd16022740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device.\n",
      "Using 8 dataloader workers every process\n",
      "using 2303 images for training, 768 images for validation.\n",
      "train epoch[1/3] loss:0.389: 100%|███████████████████████████████████████████████████| 144/144 [05:43<00:00,  2.39s/it]\n",
      "valid epoch[1/3]: 100%|████████████████████████████████████████████████████████████████| 48/48 [00:44<00:00,  1.07it/s]\n",
      "[epoch 1] train_loss: 0.556  val_accuracy: 0.871\n",
      "train epoch[2/3] loss:0.449: 100%|███████████████████████████████████████████████████| 144/144 [05:38<00:00,  2.35s/it]\n",
      "valid epoch[2/3]: 100%|████████████████████████████████████████████████████████████████| 48/48 [00:44<00:00,  1.07it/s]\n",
      "[epoch 2] train_loss: 0.380  val_accuracy: 0.931\n",
      "train epoch[3/3] loss:0.507: 100%|███████████████████████████████████████████████████| 144/144 [05:40<00:00,  2.37s/it]\n",
      "valid epoch[3/3]: 100%|████████████████████████████████████████████████████████████████| 48/48 [00:44<00:00,  1.09it/s]\n",
      "[epoch 3] train_loss: 0.326  val_accuracy: 0.924\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize(256),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "    data_root = os.path.abspath(os.path.join(os.getcwd(), \"../Miniproject\"))  # get data root path\n",
    "    image_path = os.path.join(data_root, \"genki4k\", \"files(splitdata)\")  # genki4k data set path\n",
    "    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                         transform=data_transform[\"train\"])\n",
    "    train_num = len(train_dataset)\n",
    "\n",
    "    flower_list = train_dataset.class_to_idx\n",
    "    cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(cla_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    batch_size = 16 #the number of samples to be used in each iteration\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                            transform=data_transform[\"val\"])\n",
    "    val_num = len(validate_dataset)\n",
    "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "    \n",
    "    net = resnet34()\n",
    "    # load pretrain weights\n",
    "    # download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "    model_weight_path = \"./resnet34-pre.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
    "    # for param in net.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # change fc layer structure\n",
    "    in_channel = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_channel, 5)\n",
    "    net.to(device)\n",
    "\n",
    "    # define loss function\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params, lr=0.0001)\n",
    "\n",
    "    epochs = 3\n",
    "    best_acc = 0.0\n",
    "    save_path = './resNet34.pth'\n",
    "    train_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            logits = net(images.to(device))\n",
    "            loss = loss_function(logits, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                # loss = loss_function(outputs, test_labels)\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
    "                                                           epochs)\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611046a9-9b14-4379-9a43-77a53b8eda0c",
   "metadata": {},
   "source": [
    "This is for head pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3d15874-125e-4c73-b68f-ad379cceb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Validation Loss: 0.0185\n",
      "Epoch [2/10], Validation Loss: 0.0105\n",
      "Epoch [3/10], Validation Loss: 0.0206\n",
      "Epoch [4/10], Validation Loss: 0.0112\n",
      "Epoch [5/10], Validation Loss: 0.0122\n",
      "Epoch [6/10], Validation Loss: 0.0161\n",
      "Epoch [7/10], Validation Loss: 0.0327\n",
      "Epoch [8/10], Validation Loss: 0.0143\n",
      "Epoch [9/10], Validation Loss: 0.0109\n",
      "Epoch [10/10], Validation Loss: 0.0083\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the dataset class\n",
    "class GenkiDataset(Dataset):\n",
    "    def __init__(self, labels_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(labels_file, delim_whitespace=True, header=None)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = f\"{self.img_dir}/file{idx + 1:04d}.jpg\"\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 1:4].values.astype(float)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Define the ResNet-based model\n",
    "class HeadPoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeadPoseNet, self).__init__()\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, 3)  # Output size is 3 for pitch, yaw, and roll\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "labels_file = 'genki4k/labels.txt'\n",
    "img_dir = 'genki4k/files'\n",
    "genki_dataset = GenkiDataset(labels_file=labels_file, img_dir=img_dir, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_idx, valid_idx = train_test_split(range(len(genki_dataset)), test_size=0.2, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(genki_dataset, train_idx)\n",
    "valid_dataset = torch.utils.data.Subset(genki_dataset, valid_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = HeadPoseNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for images, labels in valid_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(valid_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {average_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'headpose_resnet34_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea529cb2-9b42-4cf7-8bec-fec60401c831",
   "metadata": {},
   "source": [
    "Step4 Testing \n",
    "In this part,we will test the model on the 'test' dataset to evaluate its performance.(The detailed process is in part 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c80351-bf74-40af-9aa6-d6df0027a4fd",
   "metadata": {},
   "source": [
    "7 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacbcaf-7d1d-404f-912f-d445237f043d",
   "metadata": {},
   "source": [
    "The Genki4k dataset has 4000 images,containing expressions and head-pose labels,we split the dataset into \"train\",\"test\" and \"val\" to build a model.Before training, we need to preprocess the dataset, extract useful information from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda5cc1-ca8b-4c80-be81-f1d12f2406a6",
   "metadata": {},
   "source": [
    "'shape_predictor_68_face_landmarks.data'is a set of 68 specific points on the face. Each landmark corresponds to a specific location on the face, such as the corners of the eyes, nose, mouth, and other facial contours.We use this set to extract the face in the image which is also used to discard some irrelevant noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4393e65d-361d-431b-9763-75cc48777821",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5409b4-050a-46a5-821a-451fbb6ea658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing done!\n"
     ]
    }
   ],
   "source": [
    "path_read = \"genki4k/files\"\n",
    "num=0\n",
    "for file_name in os.listdir(path_read):\n",
    "    all_path = (path_read + \"/\" + file_name)\n",
    "    img = cv2.imdecode(np.fromfile(all_path, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "    # get width and height\n",
    "    img_shape=img.shape\n",
    "    img_height=img_shape[0]\n",
    "    img_width=img_shape[1]\n",
    "   \n",
    "    os.makedirs(\"genki4k/files(preprocess)\", exist_ok=True)#store each single face\n",
    "    path_save = \"genki4k/files(preprocess)\"\n",
    "    # dlib detection\n",
    "    dets = detector(img , 1)\n",
    "    for k, d in enumerate(dets):\n",
    "        if len(dets) > 1:\n",
    "            continue\n",
    "        num=num+1\n",
    "        \n",
    "        # record the position\n",
    "        pos_start = tuple([d.left(), d.top()])\n",
    "        pos_end = tuple([d.right(), d.bottom()])\n",
    " \n",
    "        # calculate the size\n",
    "        height = d.bottom()-d.top()\n",
    "        width = d.right()-d.left()\n",
    " \n",
    "        # generate a blank image and copy the pixel\n",
    "        img_blank = np.zeros((height, width, 3), np.uint8)\n",
    "        for i in range(height):\n",
    "            if d.top()+i >= img_height: # 防止越界\n",
    "                continue\n",
    "            for j in range(width):\n",
    "                if d.left()+j >= img_width: # 防止越界\n",
    "                    continue\n",
    "                img_blank[i][j] = img[d.top()+i][d.left()+j]\n",
    "        img_blank = cv2.resize(img_blank, (200, 200), interpolation=cv2.INTER_CUBIC)\n",
    " \n",
    "        cv2.imencode('.jpg', img_blank)[1].tofile(path_save+\"/\"+\"file\"+str(num)+\".jpg\") # 正确方法\n",
    " \n",
    "print(\"processing done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777111a-4d1d-4e78-9130-8bc7c72de2f7",
   "metadata": {},
   "source": [
    "#### 8 Result ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad38004-fa94-4fe6-a754-c3054b590fde",
   "metadata": {},
   "source": [
    "This is for smile-detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b660029d-975f-4bd3-9ee4-fec597d975e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: genki4k/files(splitdata)/test/unsmile\\file2168.jpg  class: unsmile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2176.jpg  class: unsmile  prob: 0.957\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2177.jpg  class: unsmile  prob: 0.977\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2187.jpg  class: unsmile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2192.jpg  class: unsmile  prob: 0.931\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2198.jpg  class: unsmile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2207.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2208.jpg  class: unsmile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2216.jpg  class: unsmile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2217.jpg  class: unsmile  prob: 0.979\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2221.jpg  class: unsmile  prob: 0.97\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2224.jpg  class: unsmile  prob: 0.871\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2227.jpg  class: unsmile  prob: 0.871\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2229.jpg  class: unsmile  prob: 0.985\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2236.jpg  class: unsmile  prob: 0.983\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2243.jpg  class: unsmile  prob: 0.903\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2250.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2266.jpg  class: unsmile  prob: 0.597\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2270.jpg  class: unsmile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2271.jpg  class: smile  prob: 0.499\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2288.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2289.jpg  class: unsmile  prob: 0.758\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2297.jpg  class: unsmile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2301.jpg  class: unsmile  prob: 0.593\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2303.jpg  class: unsmile  prob: 0.733\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2305.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2307.jpg  class: unsmile  prob: 0.975\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2324.jpg  class: smile  prob: 0.832\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2329.jpg  class: unsmile  prob: 0.596\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2338.jpg  class: unsmile  prob: 0.983\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2342.jpg  class: unsmile  prob: 0.956\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2349.jpg  class: unsmile  prob: 0.615\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2352.jpg  class: unsmile  prob: 0.964\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2355.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2362.jpg  class: unsmile  prob: 0.875\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2377.jpg  class: unsmile  prob: 0.978\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2391.jpg  class: unsmile  prob: 0.916\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2398.jpg  class: unsmile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2400.jpg  class: unsmile  prob: 0.929\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2405.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2408.jpg  class: smile  prob: 0.647\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2412.jpg  class: unsmile  prob: 0.576\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2413.jpg  class: smile  prob: 0.848\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2415.jpg  class: unsmile  prob: 0.891\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2416.jpg  class: unsmile  prob: 0.83\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2418.jpg  class: unsmile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2420.jpg  class: unsmile  prob: 0.716\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2427.jpg  class: unsmile  prob: 0.903\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2434.jpg  class: unsmile  prob: 0.962\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2436.jpg  class: smile  prob: 0.986\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2440.jpg  class: unsmile  prob: 0.767\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2443.jpg  class: unsmile  prob: 0.989\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2445.jpg  class: unsmile  prob: 0.987\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2462.jpg  class: unsmile  prob: 0.582\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2478.jpg  class: unsmile  prob: 0.938\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2482.jpg  class: unsmile  prob: 0.867\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2486.jpg  class: smile  prob: 0.513\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2488.jpg  class: unsmile  prob: 0.79\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2492.jpg  class: unsmile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2497.jpg  class: unsmile  prob: 0.975\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2502.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2507.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2512.jpg  class: unsmile  prob: 0.948\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2513.jpg  class: unsmile  prob: 0.753\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2514.jpg  class: unsmile  prob: 0.691\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2521.jpg  class: smile  prob: 0.662\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2526.jpg  class: unsmile  prob: 0.955\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2530.jpg  class: unsmile  prob: 0.92\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2535.jpg  class: unsmile  prob: 0.916\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2539.jpg  class: unsmile  prob: 0.971\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2546.jpg  class: unsmile  prob: 0.924\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2547.jpg  class: unsmile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2548.jpg  class: unsmile  prob: 0.931\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2555.jpg  class: unsmile  prob: 0.689\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2556.jpg  class: unsmile  prob: 0.769\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2562.jpg  class: unsmile  prob: 0.912\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2573.jpg  class: unsmile  prob: 0.825\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2574.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2586.jpg  class: unsmile  prob: 0.536\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2587.jpg  class: unsmile  prob: 0.779\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2589.jpg  class: unsmile  prob: 0.958\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2593.jpg  class: smile  prob: 0.843\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2596.jpg  class: unsmile  prob: 0.857\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2598.jpg  class: smile  prob: 0.644\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2603.jpg  class: unsmile  prob: 0.846\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2605.jpg  class: unsmile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2614.jpg  class: unsmile  prob: 0.891\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2618.jpg  class: smile  prob: 0.539\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2621.jpg  class: unsmile  prob: 0.716\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2622.jpg  class: unsmile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2626.jpg  class: unsmile  prob: 0.98\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2629.jpg  class: smile  prob: 0.585\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2634.jpg  class: unsmile  prob: 0.98\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2644.jpg  class: unsmile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2647.jpg  class: unsmile  prob: 0.599\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2656.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2662.jpg  class: unsmile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2663.jpg  class: unsmile  prob: 0.686\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2665.jpg  class: unsmile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2666.jpg  class: unsmile  prob: 0.627\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2680.jpg  class: unsmile  prob: 0.599\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2681.jpg  class: unsmile  prob: 0.978\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2690.jpg  class: unsmile  prob: 0.983\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2694.jpg  class: unsmile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2695.jpg  class: unsmile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2698.jpg  class: unsmile  prob: 0.74\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2701.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2707.jpg  class: unsmile  prob: 0.987\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2710.jpg  class: unsmile  prob: 0.846\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2716.jpg  class: unsmile  prob: 0.951\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2722.jpg  class: unsmile  prob: 0.871\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2726.jpg  class: unsmile  prob: 0.871\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2743.jpg  class: unsmile  prob: 0.963\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2757.jpg  class: unsmile  prob: 0.969\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2761.jpg  class: unsmile  prob: 0.989\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2765.jpg  class: unsmile  prob: 0.756\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2766.jpg  class: unsmile  prob: 0.989\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2768.jpg  class: smile  prob: 0.822\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2769.jpg  class: unsmile  prob: 0.97\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2777.jpg  class: unsmile  prob: 0.903\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2783.jpg  class: unsmile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2784.jpg  class: unsmile  prob: 0.969\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2785.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2786.jpg  class: unsmile  prob: 0.835\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2789.jpg  class: unsmile  prob: 0.966\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2791.jpg  class: unsmile  prob: 0.706\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2805.jpg  class: unsmile  prob: 0.833\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2806.jpg  class: unsmile  prob: 0.858\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2807.jpg  class: unsmile  prob: 0.778\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2814.jpg  class: unsmile  prob: 0.929\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2819.jpg  class: unsmile  prob: 0.98\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2820.jpg  class: unsmile  prob: 0.728\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2822.jpg  class: unsmile  prob: 0.774\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2823.jpg  class: unsmile  prob: 0.968\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2826.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2829.jpg  class: unsmile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2830.jpg  class: smile  prob: 0.499\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2834.jpg  class: unsmile  prob: 0.968\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2840.jpg  class: unsmile  prob: 0.809\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2841.jpg  class: unsmile  prob: 0.959\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2848.jpg  class: unsmile  prob: 0.83\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2849.jpg  class: unsmile  prob: 0.95\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2852.jpg  class: unsmile  prob: 0.969\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2856.jpg  class: unsmile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2857.jpg  class: unsmile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2863.jpg  class: unsmile  prob: 0.817\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2881.jpg  class: unsmile  prob: 0.854\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2884.jpg  class: unsmile  prob: 0.854\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2885.jpg  class: unsmile  prob: 0.931\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2895.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2898.jpg  class: unsmile  prob: 0.827\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2904.jpg  class: unsmile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2908.jpg  class: unsmile  prob: 0.891\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2910.jpg  class: unsmile  prob: 0.954\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2911.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2913.jpg  class: unsmile  prob: 0.933\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2921.jpg  class: unsmile  prob: 0.942\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2937.jpg  class: unsmile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2945.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2956.jpg  class: smile  prob: 0.503\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2962.jpg  class: unsmile  prob: 0.795\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2964.jpg  class: unsmile  prob: 0.938\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2966.jpg  class: unsmile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2974.jpg  class: unsmile  prob: 0.757\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2976.jpg  class: unsmile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2978.jpg  class: unsmile  prob: 0.552\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2980.jpg  class: unsmile  prob: 0.61\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file2987.jpg  class: smile  prob: 0.834\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3001.jpg  class: unsmile  prob: 0.981\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3002.jpg  class: unsmile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3003.jpg  class: unsmile  prob: 0.889\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3011.jpg  class: unsmile  prob: 0.985\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3013.jpg  class: unsmile  prob: 0.964\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3016.jpg  class: unsmile  prob: 0.791\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3018.jpg  class: unsmile  prob: 0.952\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3024.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3026.jpg  class: unsmile  prob: 0.935\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3027.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3028.jpg  class: unsmile  prob: 0.897\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3030.jpg  class: unsmile  prob: 0.961\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3038.jpg  class: smile  prob: 0.76\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3041.jpg  class: unsmile  prob: 0.955\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3044.jpg  class: unsmile  prob: 0.693\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3057.jpg  class: smile  prob: 0.52\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3065.jpg  class: unsmile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3072.jpg  class: unsmile  prob: 0.978\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3077.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3079.jpg  class: unsmile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3080.jpg  class: unsmile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3085.jpg  class: unsmile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3089.jpg  class: unsmile  prob: 0.944\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3095.jpg  class: unsmile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3102.jpg  class: unsmile  prob: 0.689\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3108.jpg  class: unsmile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3109.jpg  class: unsmile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3112.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3114.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3119.jpg  class: unsmile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3122.jpg  class: smile  prob: 0.604\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3126.jpg  class: unsmile  prob: 0.878\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3140.jpg  class: unsmile  prob: 0.64\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3147.jpg  class: unsmile  prob: 0.942\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3153.jpg  class: unsmile  prob: 0.867\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3157.jpg  class: unsmile  prob: 0.987\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3158.jpg  class: unsmile  prob: 0.896\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3178.jpg  class: unsmile  prob: 0.935\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3190.jpg  class: unsmile  prob: 0.942\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3199.jpg  class: unsmile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3200.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3208.jpg  class: unsmile  prob: 0.971\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3211.jpg  class: unsmile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3212.jpg  class: unsmile  prob: 0.74\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3220.jpg  class: unsmile  prob: 0.819\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3221.jpg  class: unsmile  prob: 0.972\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3228.jpg  class: unsmile  prob: 0.985\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3230.jpg  class: unsmile  prob: 0.955\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3232.jpg  class: unsmile  prob: 0.913\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3239.jpg  class: unsmile  prob: 0.952\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3242.jpg  class: unsmile  prob: 0.906\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3246.jpg  class: unsmile  prob: 0.971\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3250.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3263.jpg  class: unsmile  prob: 0.869\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3268.jpg  class: unsmile  prob: 0.508\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3269.jpg  class: unsmile  prob: 0.784\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3276.jpg  class: unsmile  prob: 0.601\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3285.jpg  class: unsmile  prob: 0.908\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3288.jpg  class: unsmile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3290.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3297.jpg  class: unsmile  prob: 0.925\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3298.jpg  class: unsmile  prob: 0.978\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3299.jpg  class: unsmile  prob: 0.92\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3303.jpg  class: smile  prob: 0.517\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3304.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3309.jpg  class: unsmile  prob: 0.975\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3317.jpg  class: unsmile  prob: 0.985\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3319.jpg  class: unsmile  prob: 0.836\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3326.jpg  class: unsmile  prob: 0.864\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3334.jpg  class: unsmile  prob: 0.875\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3335.jpg  class: unsmile  prob: 0.856\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3339.jpg  class: unsmile  prob: 0.923\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3345.jpg  class: unsmile  prob: 0.989\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3348.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3357.jpg  class: unsmile  prob: 0.956\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3362.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3369.jpg  class: unsmile  prob: 0.689\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3378.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3381.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3383.jpg  class: unsmile  prob: 0.959\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3391.jpg  class: unsmile  prob: 0.968\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3392.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3397.jpg  class: unsmile  prob: 0.603\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3399.jpg  class: unsmile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3407.jpg  class: unsmile  prob: 0.964\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3424.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3425.jpg  class: unsmile  prob: 0.783\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3426.jpg  class: unsmile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3432.jpg  class: unsmile  prob: 0.938\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3433.jpg  class: unsmile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3437.jpg  class: unsmile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3449.jpg  class: unsmile  prob: 0.6\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3452.jpg  class: unsmile  prob: 0.944\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3454.jpg  class: unsmile  prob: 0.813\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3461.jpg  class: unsmile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3466.jpg  class: smile  prob: 0.736\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3470.jpg  class: unsmile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3473.jpg  class: unsmile  prob: 0.579\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3478.jpg  class: unsmile  prob: 0.849\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3482.jpg  class: smile  prob: 0.623\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3483.jpg  class: unsmile  prob: 0.867\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3487.jpg  class: unsmile  prob: 0.658\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3498.jpg  class: unsmile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3499.jpg  class: unsmile  prob: 0.97\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3505.jpg  class: unsmile  prob: 0.966\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3506.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3509.jpg  class: unsmile  prob: 0.697\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3510.jpg  class: unsmile  prob: 0.845\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3514.jpg  class: unsmile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3519.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3521.jpg  class: unsmile  prob: 0.85\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3522.jpg  class: unsmile  prob: 0.92\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3533.jpg  class: unsmile  prob: 0.956\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3545.jpg  class: unsmile  prob: 0.615\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3548.jpg  class: unsmile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3554.jpg  class: unsmile  prob: 0.987\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3560.jpg  class: unsmile  prob: 0.787\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3568.jpg  class: unsmile  prob: 0.941\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3571.jpg  class: unsmile  prob: 0.861\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3572.jpg  class: unsmile  prob: 0.878\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3578.jpg  class: smile  prob: 0.767\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3581.jpg  class: smile  prob: 0.817\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3585.jpg  class: unsmile  prob: 0.884\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3588.jpg  class: unsmile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3596.jpg  class: unsmile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3602.jpg  class: unsmile  prob: 0.594\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3607.jpg  class: unsmile  prob: 0.823\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3609.jpg  class: unsmile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3616.jpg  class: unsmile  prob: 0.894\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3619.jpg  class: unsmile  prob: 0.681\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3624.jpg  class: unsmile  prob: 0.969\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3626.jpg  class: unsmile  prob: 0.831\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3629.jpg  class: unsmile  prob: 0.962\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3634.jpg  class: unsmile  prob: 0.975\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3638.jpg  class: unsmile  prob: 0.897\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3640.jpg  class: unsmile  prob: 0.601\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3648.jpg  class: smile  prob: 0.571\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3650.jpg  class: unsmile  prob: 0.894\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3660.jpg  class: unsmile  prob: 0.711\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3661.jpg  class: unsmile  prob: 0.695\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3663.jpg  class: unsmile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3675.jpg  class: smile  prob: 0.686\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3676.jpg  class: unsmile  prob: 0.986\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3678.jpg  class: unsmile  prob: 0.918\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3682.jpg  class: unsmile  prob: 0.979\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3688.jpg  class: unsmile  prob: 0.739\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3694.jpg  class: unsmile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3701.jpg  class: unsmile  prob: 0.69\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3706.jpg  class: unsmile  prob: 0.928\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3708.jpg  class: unsmile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3712.jpg  class: smile  prob: 0.559\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3723.jpg  class: unsmile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3724.jpg  class: unsmile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3725.jpg  class: unsmile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3726.jpg  class: unsmile  prob: 0.876\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3733.jpg  class: unsmile  prob: 0.945\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3744.jpg  class: unsmile  prob: 0.882\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3749.jpg  class: unsmile  prob: 0.894\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3767.jpg  class: unsmile  prob: 0.832\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3776.jpg  class: unsmile  prob: 0.989\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3782.jpg  class: unsmile  prob: 0.985\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3787.jpg  class: unsmile  prob: 0.987\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3801.jpg  class: unsmile  prob: 0.594\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3804.jpg  class: unsmile  prob: 0.971\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3806.jpg  class: smile  prob: 0.865\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3831.jpg  class: unsmile  prob: 0.983\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3834.jpg  class: unsmile  prob: 0.939\n",
      "image: genki4k/files(splitdata)/test/unsmile\\file3839.jpg  class: unsmile  prob: 0.835\n",
      "image: genki4k/files(splitdata)/test/smile\\file1001.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1005.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1007.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1008.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1016.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1017.jpg  class: smile  prob: 0.948\n",
      "image: genki4k/files(splitdata)/test/smile\\file102.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1023.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1026.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file103.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1032.jpg  class: unsmile  prob: 0.782\n",
      "image: genki4k/files(splitdata)/test/smile\\file1041.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1043.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1050.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1055.jpg  class: smile  prob: 0.953\n",
      "image: genki4k/files(splitdata)/test/smile\\file1058.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1059.jpg  class: unsmile  prob: 0.823\n",
      "image: genki4k/files(splitdata)/test/smile\\file1061.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1062.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1065.jpg  class: smile  prob: 0.724\n",
      "image: genki4k/files(splitdata)/test/smile\\file107.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file1071.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1079.jpg  class: unsmile  prob: 0.839\n",
      "image: genki4k/files(splitdata)/test/smile\\file1085.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1086.jpg  class: smile  prob: 0.979\n",
      "image: genki4k/files(splitdata)/test/smile\\file1088.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1092.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file11.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file110.jpg  class: smile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/smile\\file1100.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1105.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1115.jpg  class: smile  prob: 0.517\n",
      "image: genki4k/files(splitdata)/test/smile\\file1127.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1128.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1129.jpg  class: smile  prob: 0.946\n",
      "image: genki4k/files(splitdata)/test/smile\\file1131.jpg  class: smile  prob: 0.942\n",
      "image: genki4k/files(splitdata)/test/smile\\file1134.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file114.jpg  class: smile  prob: 0.719\n",
      "image: genki4k/files(splitdata)/test/smile\\file1142.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1143.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1152.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1155.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1157.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file1159.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file116.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1169.jpg  class: unsmile  prob: 0.857\n",
      "image: genki4k/files(splitdata)/test/smile\\file1181.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1192.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1193.jpg  class: smile  prob: 0.972\n",
      "image: genki4k/files(splitdata)/test/smile\\file1196.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1197.jpg  class: unsmile  prob: 0.624\n",
      "image: genki4k/files(splitdata)/test/smile\\file1199.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1202.jpg  class: smile  prob: 0.776\n",
      "image: genki4k/files(splitdata)/test/smile\\file1203.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1206.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1210.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1226.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file1233.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1234.jpg  class: smile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/smile\\file1239.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file124.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1240.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file1242.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1256.jpg  class: smile  prob: 0.986\n",
      "image: genki4k/files(splitdata)/test/smile\\file126.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1262.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1263.jpg  class: smile  prob: 0.963\n",
      "image: genki4k/files(splitdata)/test/smile\\file1269.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1270.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file1275.jpg  class: smile  prob: 0.819\n",
      "image: genki4k/files(splitdata)/test/smile\\file1278.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1279.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1285.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file1293.jpg  class: smile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/smile\\file1297.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1304.jpg  class: smile  prob: 0.87\n",
      "image: genki4k/files(splitdata)/test/smile\\file1306.jpg  class: smile  prob: 0.821\n",
      "image: genki4k/files(splitdata)/test/smile\\file1312.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file1315.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1317.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1322.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1325.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1329.jpg  class: smile  prob: 0.968\n",
      "image: genki4k/files(splitdata)/test/smile\\file1332.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1336.jpg  class: smile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/smile\\file1337.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1340.jpg  class: unsmile  prob: 0.745\n",
      "image: genki4k/files(splitdata)/test/smile\\file1350.jpg  class: smile  prob: 0.917\n",
      "image: genki4k/files(splitdata)/test/smile\\file1359.jpg  class: smile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/smile\\file1360.jpg  class: smile  prob: 0.788\n",
      "image: genki4k/files(splitdata)/test/smile\\file1363.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1367.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file137.jpg  class: smile  prob: 0.765\n",
      "image: genki4k/files(splitdata)/test/smile\\file1372.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file139.jpg  class: smile  prob: 0.93\n",
      "image: genki4k/files(splitdata)/test/smile\\file1390.jpg  class: smile  prob: 0.906\n",
      "image: genki4k/files(splitdata)/test/smile\\file1394.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1396.jpg  class: smile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/smile\\file1401.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1412.jpg  class: smile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/smile\\file1413.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1414.jpg  class: smile  prob: 0.983\n",
      "image: genki4k/files(splitdata)/test/smile\\file1417.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file1422.jpg  class: unsmile  prob: 0.769\n",
      "image: genki4k/files(splitdata)/test/smile\\file1428.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1429.jpg  class: smile  prob: 0.831\n",
      "image: genki4k/files(splitdata)/test/smile\\file143.jpg  class: smile  prob: 0.853\n",
      "image: genki4k/files(splitdata)/test/smile\\file1434.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1435.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1437.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1441.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1442.jpg  class: unsmile  prob: 0.798\n",
      "image: genki4k/files(splitdata)/test/smile\\file1444.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1445.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1455.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1456.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1466.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file1468.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1472.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1477.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1483.jpg  class: smile  prob: 0.987\n",
      "image: genki4k/files(splitdata)/test/smile\\file1484.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1487.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1493.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file15.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1500.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1506.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1517.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1523.jpg  class: smile  prob: 0.719\n",
      "image: genki4k/files(splitdata)/test/smile\\file1524.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1540.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file1543.jpg  class: smile  prob: 0.675\n",
      "image: genki4k/files(splitdata)/test/smile\\file1544.jpg  class: smile  prob: 0.883\n",
      "image: genki4k/files(splitdata)/test/smile\\file1553.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1563.jpg  class: smile  prob: 0.977\n",
      "image: genki4k/files(splitdata)/test/smile\\file1565.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1567.jpg  class: smile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/smile\\file1577.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1579.jpg  class: unsmile  prob: 0.831\n",
      "image: genki4k/files(splitdata)/test/smile\\file1587.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file159.jpg  class: smile  prob: 0.971\n",
      "image: genki4k/files(splitdata)/test/smile\\file1591.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1595.jpg  class: smile  prob: 0.625\n",
      "image: genki4k/files(splitdata)/test/smile\\file1597.jpg  class: smile  prob: 0.82\n",
      "image: genki4k/files(splitdata)/test/smile\\file1599.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file16.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1606.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1609.jpg  class: unsmile  prob: 0.741\n",
      "image: genki4k/files(splitdata)/test/smile\\file1612.jpg  class: smile  prob: 0.936\n",
      "image: genki4k/files(splitdata)/test/smile\\file1614.jpg  class: smile  prob: 0.973\n",
      "image: genki4k/files(splitdata)/test/smile\\file1616.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file1623.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1624.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1626.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1629.jpg  class: smile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/smile\\file1634.jpg  class: smile  prob: 0.989\n",
      "image: genki4k/files(splitdata)/test/smile\\file1639.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1640.jpg  class: smile  prob: 0.972\n",
      "image: genki4k/files(splitdata)/test/smile\\file1648.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file166.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1669.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file167.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1677.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file1680.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1691.jpg  class: smile  prob: 0.988\n",
      "image: genki4k/files(splitdata)/test/smile\\file1698.jpg  class: unsmile  prob: 0.55\n",
      "image: genki4k/files(splitdata)/test/smile\\file17.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1701.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1704.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1705.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1710.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1716.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1717.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1718.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1729.jpg  class: unsmile  prob: 0.624\n",
      "image: genki4k/files(splitdata)/test/smile\\file173.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file1734.jpg  class: unsmile  prob: 0.949\n",
      "image: genki4k/files(splitdata)/test/smile\\file1736.jpg  class: smile  prob: 0.986\n",
      "image: genki4k/files(splitdata)/test/smile\\file1738.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1739.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1740.jpg  class: smile  prob: 0.583\n",
      "image: genki4k/files(splitdata)/test/smile\\file1748.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file175.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1750.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1761.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1769.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1773.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1774.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1775.jpg  class: smile  prob: 0.817\n",
      "image: genki4k/files(splitdata)/test/smile\\file1780.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1782.jpg  class: smile  prob: 0.959\n",
      "image: genki4k/files(splitdata)/test/smile\\file1785.jpg  class: smile  prob: 0.895\n",
      "image: genki4k/files(splitdata)/test/smile\\file1810.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1820.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1822.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1824.jpg  class: smile  prob: 0.633\n",
      "image: genki4k/files(splitdata)/test/smile\\file1831.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file1832.jpg  class: unsmile  prob: 0.712\n",
      "image: genki4k/files(splitdata)/test/smile\\file1833.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1841.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1844.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1845.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1852.jpg  class: smile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/smile\\file1854.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file1856.jpg  class: smile  prob: 0.505\n",
      "image: genki4k/files(splitdata)/test/smile\\file1860.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file1866.jpg  class: smile  prob: 0.96\n",
      "image: genki4k/files(splitdata)/test/smile\\file1869.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1886.jpg  class: smile  prob: 0.698\n",
      "image: genki4k/files(splitdata)/test/smile\\file1891.jpg  class: smile  prob: 0.946\n",
      "image: genki4k/files(splitdata)/test/smile\\file1900.jpg  class: smile  prob: 0.962\n",
      "image: genki4k/files(splitdata)/test/smile\\file1909.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file191.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1911.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1912.jpg  class: smile  prob: 0.513\n",
      "image: genki4k/files(splitdata)/test/smile\\file1914.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1916.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file1917.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file1919.jpg  class: smile  prob: 0.961\n",
      "image: genki4k/files(splitdata)/test/smile\\file1920.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file1922.jpg  class: smile  prob: 0.52\n",
      "image: genki4k/files(splitdata)/test/smile\\file1931.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file1936.jpg  class: smile  prob: 0.823\n",
      "image: genki4k/files(splitdata)/test/smile\\file1938.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1945.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1951.jpg  class: unsmile  prob: 0.526\n",
      "image: genki4k/files(splitdata)/test/smile\\file1957.jpg  class: smile  prob: 0.984\n",
      "image: genki4k/files(splitdata)/test/smile\\file1961.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file1969.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1974.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1977.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file198.jpg  class: smile  prob: 0.921\n",
      "image: genki4k/files(splitdata)/test/smile\\file1982.jpg  class: smile  prob: 0.925\n",
      "image: genki4k/files(splitdata)/test/smile\\file1983.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1985.jpg  class: smile  prob: 0.977\n",
      "image: genki4k/files(splitdata)/test/smile\\file1986.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file1990.jpg  class: smile  prob: 0.533\n",
      "image: genki4k/files(splitdata)/test/smile\\file200.jpg  class: smile  prob: 0.969\n",
      "image: genki4k/files(splitdata)/test/smile\\file2000.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2007.jpg  class: smile  prob: 0.888\n",
      "image: genki4k/files(splitdata)/test/smile\\file2009.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file201.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2025.jpg  class: smile  prob: 0.942\n",
      "image: genki4k/files(splitdata)/test/smile\\file2026.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file2029.jpg  class: smile  prob: 0.956\n",
      "image: genki4k/files(splitdata)/test/smile\\file2034.jpg  class: smile  prob: 0.896\n",
      "image: genki4k/files(splitdata)/test/smile\\file2037.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2038.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2043.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file2044.jpg  class: smile  prob: 0.933\n",
      "image: genki4k/files(splitdata)/test/smile\\file2046.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file2047.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file2051.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2054.jpg  class: unsmile  prob: 0.818\n",
      "image: genki4k/files(splitdata)/test/smile\\file2055.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file206.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2063.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file207.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file2071.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2079.jpg  class: smile  prob: 0.892\n",
      "image: genki4k/files(splitdata)/test/smile\\file2081.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file2083.jpg  class: unsmile  prob: 0.969\n",
      "image: genki4k/files(splitdata)/test/smile\\file2085.jpg  class: smile  prob: 0.95\n",
      "image: genki4k/files(splitdata)/test/smile\\file2086.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file2091.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2092.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2093.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file2098.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file2100.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file2106.jpg  class: smile  prob: 0.924\n",
      "image: genki4k/files(splitdata)/test/smile\\file2109.jpg  class: smile  prob: 0.95\n",
      "image: genki4k/files(splitdata)/test/smile\\file2110.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file2117.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file213.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file221.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file225.jpg  class: smile  prob: 0.715\n",
      "image: genki4k/files(splitdata)/test/smile\\file231.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file234.jpg  class: smile  prob: 0.954\n",
      "image: genki4k/files(splitdata)/test/smile\\file235.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file238.jpg  class: smile  prob: 0.82\n",
      "image: genki4k/files(splitdata)/test/smile\\file241.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file250.jpg  class: smile  prob: 0.974\n",
      "image: genki4k/files(splitdata)/test/smile\\file251.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file263.jpg  class: unsmile  prob: 0.762\n",
      "image: genki4k/files(splitdata)/test/smile\\file265.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file27.jpg  class: smile  prob: 0.813\n",
      "image: genki4k/files(splitdata)/test/smile\\file271.jpg  class: smile  prob: 0.967\n",
      "image: genki4k/files(splitdata)/test/smile\\file272.jpg  class: smile  prob: 0.946\n",
      "image: genki4k/files(splitdata)/test/smile\\file286.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file288.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file289.jpg  class: smile  prob: 0.881\n",
      "image: genki4k/files(splitdata)/test/smile\\file294.jpg  class: smile  prob: 0.981\n",
      "image: genki4k/files(splitdata)/test/smile\\file296.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file304.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file306.jpg  class: smile  prob: 0.905\n",
      "image: genki4k/files(splitdata)/test/smile\\file309.jpg  class: smile  prob: 0.977\n",
      "image: genki4k/files(splitdata)/test/smile\\file317.jpg  class: smile  prob: 0.524\n",
      "image: genki4k/files(splitdata)/test/smile\\file318.jpg  class: smile  prob: 0.972\n",
      "image: genki4k/files(splitdata)/test/smile\\file322.jpg  class: smile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/smile\\file330.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file345.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file350.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file351.jpg  class: smile  prob: 0.964\n",
      "image: genki4k/files(splitdata)/test/smile\\file355.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file358.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file372.jpg  class: smile  prob: 0.952\n",
      "image: genki4k/files(splitdata)/test/smile\\file378.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file38.jpg  class: smile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/smile\\file381.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file386.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file40.jpg  class: smile  prob: 0.701\n",
      "image: genki4k/files(splitdata)/test/smile\\file400.jpg  class: smile  prob: 0.748\n",
      "image: genki4k/files(splitdata)/test/smile\\file404.jpg  class: smile  prob: 0.972\n",
      "image: genki4k/files(splitdata)/test/smile\\file41.jpg  class: smile  prob: 0.837\n",
      "image: genki4k/files(splitdata)/test/smile\\file423.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file427.jpg  class: smile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/smile\\file432.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file439.jpg  class: unsmile  prob: 0.887\n",
      "image: genki4k/files(splitdata)/test/smile\\file443.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file447.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file452.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file461.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file469.jpg  class: smile  prob: 0.584\n",
      "image: genki4k/files(splitdata)/test/smile\\file471.jpg  class: unsmile  prob: 0.633\n",
      "image: genki4k/files(splitdata)/test/smile\\file482.jpg  class: smile  prob: 0.97\n",
      "image: genki4k/files(splitdata)/test/smile\\file486.jpg  class: smile  prob: 0.966\n",
      "image: genki4k/files(splitdata)/test/smile\\file488.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file490.jpg  class: smile  prob: 0.911\n",
      "image: genki4k/files(splitdata)/test/smile\\file491.jpg  class: smile  prob: 0.981\n",
      "image: genki4k/files(splitdata)/test/smile\\file501.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file503.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file506.jpg  class: smile  prob: 0.961\n",
      "image: genki4k/files(splitdata)/test/smile\\file508.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file515.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file524.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file527.jpg  class: smile  prob: 0.798\n",
      "image: genki4k/files(splitdata)/test/smile\\file53.jpg  class: smile  prob: 0.581\n",
      "image: genki4k/files(splitdata)/test/smile\\file531.jpg  class: smile  prob: 0.563\n",
      "image: genki4k/files(splitdata)/test/smile\\file542.jpg  class: smile  prob: 0.975\n",
      "image: genki4k/files(splitdata)/test/smile\\file545.jpg  class: smile  prob: 0.659\n",
      "image: genki4k/files(splitdata)/test/smile\\file546.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file550.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file568.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file569.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file58.jpg  class: smile  prob: 0.929\n",
      "image: genki4k/files(splitdata)/test/smile\\file582.jpg  class: smile  prob: 0.888\n",
      "image: genki4k/files(splitdata)/test/smile\\file583.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file585.jpg  class: smile  prob: 0.777\n",
      "image: genki4k/files(splitdata)/test/smile\\file586.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file594.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file595.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file597.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file598.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file601.jpg  class: smile  prob: 0.99\n",
      "image: genki4k/files(splitdata)/test/smile\\file603.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file604.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file605.jpg  class: smile  prob: 0.636\n",
      "image: genki4k/files(splitdata)/test/smile\\file606.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file61.jpg  class: smile  prob: 0.955\n",
      "image: genki4k/files(splitdata)/test/smile\\file611.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file62.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file620.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file622.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file637.jpg  class: smile  prob: 0.861\n",
      "image: genki4k/files(splitdata)/test/smile\\file641.jpg  class: smile  prob: 0.982\n",
      "image: genki4k/files(splitdata)/test/smile\\file649.jpg  class: smile  prob: 0.965\n",
      "image: genki4k/files(splitdata)/test/smile\\file653.jpg  class: smile  prob: 0.993\n",
      "image: genki4k/files(splitdata)/test/smile\\file669.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file676.jpg  class: smile  prob: 0.935\n",
      "image: genki4k/files(splitdata)/test/smile\\file680.jpg  class: smile  prob: 0.942\n",
      "image: genki4k/files(splitdata)/test/smile\\file682.jpg  class: smile  prob: 0.995\n",
      "image: genki4k/files(splitdata)/test/smile\\file705.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file713.jpg  class: smile  prob: 0.991\n",
      "image: genki4k/files(splitdata)/test/smile\\file719.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file725.jpg  class: smile  prob: 0.843\n",
      "image: genki4k/files(splitdata)/test/smile\\file726.jpg  class: smile  prob: 0.992\n",
      "image: genki4k/files(splitdata)/test/smile\\file730.jpg  class: unsmile  prob: 0.779\n",
      "image: genki4k/files(splitdata)/test/smile\\file732.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file733.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file734.jpg  class: unsmile  prob: 0.71\n",
      "image: genki4k/files(splitdata)/test/smile\\file736.jpg  class: smile  prob: 0.577\n",
      "image: genki4k/files(splitdata)/test/smile\\file743.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file751.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file754.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file766.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file770.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file775.jpg  class: smile  prob: 0.962\n",
      "image: genki4k/files(splitdata)/test/smile\\file785.jpg  class: unsmile  prob: 0.797\n",
      "image: genki4k/files(splitdata)/test/smile\\file787.jpg  class: smile  prob: 0.996\n",
      "image: genki4k/files(splitdata)/test/smile\\file794.jpg  class: smile  prob: 0.918\n",
      "image: genki4k/files(splitdata)/test/smile\\file809.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file813.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file816.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file817.jpg  class: smile  prob: 0.983\n",
      "image: genki4k/files(splitdata)/test/smile\\file825.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file826.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file832.jpg  class: smile  prob: 0.986\n",
      "image: genki4k/files(splitdata)/test/smile\\file833.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file836.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file839.jpg  class: smile  prob: 0.994\n",
      "image: genki4k/files(splitdata)/test/smile\\file846.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file85.jpg  class: unsmile  prob: 0.503\n",
      "image: genki4k/files(splitdata)/test/smile\\file859.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file875.jpg  class: smile  prob: 0.962\n",
      "image: genki4k/files(splitdata)/test/smile\\file881.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file887.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file889.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file900.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file911.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file912.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file914.jpg  class: unsmile  prob: 0.902\n",
      "image: genki4k/files(splitdata)/test/smile\\file926.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file927.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file93.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file950.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file961.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file969.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file977.jpg  class: smile  prob: 0.998\n",
      "image: genki4k/files(splitdata)/test/smile\\file98.jpg  class: smile  prob: 1.0\n",
      "image: genki4k/files(splitdata)/test/smile\\file980.jpg  class: smile  prob: 0.997\n",
      "image: genki4k/files(splitdata)/test/smile\\file984.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file987.jpg  class: unsmile  prob: 0.504\n",
      "image: genki4k/files(splitdata)/test/smile\\file990.jpg  class: smile  prob: 0.999\n",
      "image: genki4k/files(splitdata)/test/smile\\file991.jpg  class: smile  prob: 0.999\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from model import resnet34\n",
    "\n",
    "\n",
    "def main(imgs_root):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data_transform = transforms.Compose(\n",
    "        [transforms.Resize(256),\n",
    "         transforms.CenterCrop(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    # load image\n",
    "    # 指向需要遍历预测的图像文件夹\n",
    "    # imgs_root = \"genki4k/files(splitdata)/test/unsmile\"\n",
    "    # imgs_root = \"genki4k/files(splitdata)/test/smile\"\n",
    "    assert os.path.exists(imgs_root), f\"file: '{imgs_root}' dose not exist.\"\n",
    "    # 读取指定文件夹下所有jpg图像路径\n",
    "    img_path_list = [os.path.join(imgs_root, i) for i in os.listdir(imgs_root) if i.endswith(\".jpg\")]\n",
    "\n",
    "    # read class_indict\n",
    "    json_path = './class_indices.json'\n",
    "    assert os.path.exists(json_path), f\"file: '{json_path}' dose not exist.\"\n",
    "\n",
    "    json_file = open(json_path, \"r\")\n",
    "    class_indict = json.load(json_file)\n",
    "\n",
    "    # create model\n",
    "    model = resnet34(num_classes=5).to(device)\n",
    "\n",
    "    # load model weights\n",
    "    weights_path = \"./resNet34.pth\"\n",
    "    assert os.path.exists(weights_path), f\"file: '{weights_path}' dose not exist.\"\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "\n",
    "    # prediction\n",
    "    model.eval()\n",
    "    batch_size = 8  # 每次预测时将多少张图片打包成一个batch\n",
    "    with torch.no_grad():\n",
    "        for ids in range(0, len(img_path_list) // batch_size):\n",
    "            img_list = []\n",
    "            for img_path in img_path_list[ids * batch_size: (ids + 1) * batch_size]:\n",
    "                assert os.path.exists(img_path), f\"file: '{img_path}' dose not exist.\"\n",
    "                img = Image.open(img_path)\n",
    "                img = data_transform(img)\n",
    "                img_list.append(img)\n",
    "\n",
    "            # batch img\n",
    "            # 将img_list列表中的所有图像打包成一个batch\n",
    "            batch_img = torch.stack(img_list, dim=0)\n",
    "            # predict class\n",
    "            output = model(batch_img.to(device)).cpu()\n",
    "            predict = torch.softmax(output, dim=1)\n",
    "            probs, classes = torch.max(predict, dim=1)\n",
    "            for idx, (pro, cla) in enumerate(zip(probs, classes)):\n",
    "                print(\"image: {}  class: {}  prob: {:.3}\".format(img_path_list[ids * batch_size + idx],\n",
    "                                                                 class_indict[str(cla.numpy())],\n",
    "                                                                 pro.numpy()))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(\"genki4k/files(splitdata)/test/unsmile\")\n",
    "    main(\"genki4k/files(splitdata)/test/smile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99ee0e-b3b6-4143-9feb-34fa7055fdaa",
   "metadata": {},
   "source": [
    "In summary, in binary classification, a decision threshold is used to determine the class assignment based on the model's predicted probabilities, which is prosterior probability, it will belongs to the class that has higher probability. Actually we don't know the true prosterior probablity, which can only derived by Bayesian classification.\n",
    "In smile-detection, at last we can evaluate the model on the test dataset. After calculation, we can get the test misclassification rate = (32+25 /(425+343)*100%=7.42%, so we have the test accuracy=92.58%.\n",
    "I reviewed the picture of the error in judgement and concluded that there were several possible reasons for the error:\n",
    "1.It is difficult to judge whether a smile and its emotions are present in the picture itself, and it is possible to misjudge it even by direct human observation.\n",
    "2.Some actions interfere with categorisation, e.g. opening the mouth and showing the teeth is similar to smiling with the teeth open.\n",
    "3.It is still affected by light and shadow, etc, noise immunity of the model needs to be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3fa2cbc-b052-45a0-8b29-0d3509f7e352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predictions:\n",
      "[[-0.01750545  0.04791921 -0.03983924]\n",
      " [-0.10934243  0.07142161 -0.10967906]\n",
      " [ 0.03334953  0.00484018  0.06744011]\n",
      " ...\n",
      " [ 0.2679275   0.00716439 -0.02689921]\n",
      " [-0.12705871  0.01254077  0.07153283]\n",
      " [-0.10002096 -0.00118944 -0.07318167]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from headpose2 import HeadPoseNet\n",
    "\n",
    "\n",
    "# Define the dataset class (similar to the training dataset class)\n",
    "class TestGenkiDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.num_samples = 1000  # Set the number of test samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = f\"{self.img_dir}/file{idx + 1:04d}.jpg\"\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Load the trained model\n",
    "model = HeadPoseNet()\n",
    "model.load_state_dict(torch.load('headpose_resnet34_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Define transformations for test images\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the test dataset and dataloader\n",
    "test_img_dir = 'genki4k/files'  # Provide the path to the directory containing test images\n",
    "test_dataset = TestGenkiDataset(img_dir=test_img_dir, transform=test_transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Test the model\n",
    "model_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        outputs = model(images)\n",
    "        model_predictions.append(outputs.numpy())\n",
    "\n",
    "# Concatenate the predictions from different batches\n",
    "model_predictions = np.concatenate(model_predictions, axis=0)\n",
    "\n",
    "# Display or further process the predictions as needed\n",
    "print(\"Model Predictions:\")\n",
    "print(model_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9baae-d699-4195-aee7-a80d92a102f2",
   "metadata": {},
   "source": [
    "And we can use these code to calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca4e97-ce16-4e14-873b-c5ac0aba16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Test the model\n",
    "total_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        outputs = model(images)\n",
    "        # Assuming true_labels is a tensor containing the true labels for the batch\n",
    "        loss = criterion(outputs, true_labels[num_batches * test_loader.batch_size: (num_batches + 1) * test_loader.batch_size])\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "# Calculate the average loss\n",
    "average_loss = total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fe06d-c95c-4d02-a6c7-25a478d5cc29",
   "metadata": {},
   "source": [
    "As for head pose estimation\n",
    "We use loss to assess the performance of the model. In regression models, loss usually refers to the MSE, or Mean Square Error, which is usually as small as possible, sometimes with some adjustments depending on the robustness generalisability of the model.\n",
    "In this experiment, we can see that the validation loss always around 0.01, which shows an excellent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721d703-19d9-4eb1-967a-81abcce821e4",
   "metadata": {},
   "source": [
    "#### 9 Conlusions ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d223ed-6225-44e9-9e36-d31fadfd1902",
   "metadata": {},
   "source": [
    "1.To do a machine learning project, at first we should figure out the problem and choose a suitable method, supervised or unsupervised, classification or regression, density estimation or structure analysis.\n",
    "2.Do some preprocess, all kinds of data augmentation and normalization to make the data more suitable for training.\n",
    "3.Choose a suitable, it depend on the specific need, different weight of data and different input and output use different models,sometimes we need to mix them.\n",
    "4.Train your model and evaluate it through some standard,MSE,Cross-Entropy loss and so on.Remember test it on the test dataset preventing overfitting.\n",
    "5.Analyze the result and try to improve, no matter in datasets or methodology."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
